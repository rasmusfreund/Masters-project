@article{hintonConnectionistLearningProcedures1989,
  title = {Connectionist Learning Procedures},
  author = {Hinton, Geoffrey E.},
  date = {1989-09},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {40},
  number = {1-3},
  pages = {185--234},
  issn = {00043702},
  doi = {10.1016/0004-3702(89)90049-0},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0004370289900490},
  urldate = {2024-05-23},
  abstract = {A major goal of research on networks of neuron-like processing units is to discover efficient learning procedures that allow these networks to construct complex internal representations of their environment. The learning procedures must be capable of modifying the connection strengths in such a way that internal units which are not part of the input or output come to represent important features of the task domain. Several interesting gradient-descent procedures have recently been discovered. Each connection computes the derivative, with respect to the connection strength, of a global measure of the error in the performance of the network. The strength is then adjusted in the direction that decreases the error. These relatively simple, gradient-descent learning procedures work well for small tasks and the new challenge is to find ways of improving their convergence rate and their generalization abilities so that they can be applied to larger, more realistic tasks.},
  langid = {english},
  file = {C:\Users\rasmu\Zotero\storage\SUIRSVM9\Hinton - 1989 - Connectionist learning procedures.pdf}
}
